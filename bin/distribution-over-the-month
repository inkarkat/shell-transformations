#!/bin/bash

printShortUsage()
{
    # Note: short followed by long option; if the user knows the short one, she can
    # skim the long one.
    printf "Usage: echo -e '2021-12-31 11:01\\\\n2022-01-11 12:00\\\\n...'| [DISTRIBUTIONOVERTHEMONTH_EMPTY_CELL='-'] [DISTRIBUTIONOVERTHEMONTH_BORDERS='/ \ L J'] [DISTRIBUTIONOVERTHEMONTH_LEGEND_LENGTH=N] %q %s\\n" "$(basename "$1")" '[--no-footer|--final-footer-only|--footer-only-on-change|--footer-every N] [--graph-legend TEXT] [--graph-field N] [--footer-legend TEXT] [--footer-field N] [-F|--field-separator FS] [--day-field N] [--slots-per-day N [--hour-field M]] [--count-field C [--default-count C|""]] [--split-graph-field N [--split-graph-field ...]] [--as colorbox-calendar|green-[large-]calendar] [SPARK-ARGS ...] [-?|-h|--help]'
}
printUsage()
{
    # This is the short help when launched with no or incorrect arguments.
    # It is printed to stderr to avoid accidental processing.
    printShortUsage "$1" >&2
    printf >&2 '\nTry %q --help for more information.\n' "$(basename "$1")"
}
printLongUsage()
{
    # This is the long "man page" when launched with the help argument.
    # It is printed to stdout to allow paging with 'more'.
    cat <<HELPDESCRIPTION
Print the distribution of the number of dates (and optionally times of day) that
fall into a certain slot (1 day by default) over the month; i.e. from the first
until the last day of the month. Requires the day of the month in the third
column of the data (after year and month); anything after that is ignored.
HELPDESCRIPTION
    echo
    printShortUsage "$1"
    echo
    cat <<HELPTEXT
    --no-footer		Omit the footer that shows the hours.
    --final-footer-only	Omit the footer on all graphs but the very last.
    --footer-only-on-change
			Only print a footer if it changed vs. the previous one.
			The text captured by --footer-field is not considered
			here.
    --footer-every N	Print the footer on every N'th graph. Can be combined
			with --footer-only-on-change.
    --graph-legend TEXT	Add TEXT in front of the distribution. This will also be
			the fallback text if no field value is found.
    --graph-field N	Add text captured from the first non-empty column N of
			the input data in front of the distribution.
    --footer-legend TEXT
			Add TEXT in front of the footer. If --no-footer, this
			will be put after the graph legend instead. This will
			also be the fallback text if no field value is found.
    --footer-field N	Add text captured from the first non-empty column N of
			the input data in front of the footer. If --no-footer,
			this will be put after the graph legend instead.
    --field-separator|-F FS
			Use FS for splitting the data into columns (instead of
			the default whitespace + [:_/-]).
    --day-field N	Take the day of the month from column N instead of 3.
    --count-field C	Increment the number of dates by the value found in
			column C (instead of by 1); i.e. the data already is
			pre-accumulated.
    --default-count C	Use a count of C if the count column does not contain an
			integer or is missing. Suppresses the warning that would
			normally be given then.
    --slots-per-day N	Divide each day into N slots (comprising 24 / N
			hours); default is 1 slot per day. The hour that is
			required for more than one slot is taken from the fourth
			column.
    --hour-field M	Take the hour of the day from column M instead of 4.
    --split-graph-field N
			Whenever the non-empty value of column N changes, start
			a new graph. If you want to graph every month
			separately, pass the year and month columns here.
    --as NAME-calendar	Special out-of-the-box spark style customizations.
HELPTEXT
}

typeset -a sparkArgs=()
typeset -a sparkMinArg=()
typeset -a sparkMaxArg=()
graphLegendText=
graphFieldNr=
footerLegendText=
footerFieldNr=
separator='[[:space:]:_/-]'
dayFieldNr=3
hourFieldNr=4
countFieldNr=
defaultCount=none
isFooter=t
finalFooter=
typeset -a footerCapture=()
isFooterOnlyOnChange=
footerEvery=
slotNum=1
typeset -a splitFieldNrs=()
action=
typeset -a inputDataClassificationArgs=()
typeset -a allargs=("$@")
while [ $# -ne 0 ]
do
    case "$1" in
	--help|-h|-\?)	shift; printLongUsage "$0"; exit 0;;
	--determine-count-range)
			shift; action=determineCountRange;;

	--no-footer)	shift; isFooter=;;
	--final-footer-only)
			shift; footerCapture=(-v finalFooter);;
	--footer-only-on-change)
			shift; footerCapture=(-v finalFooter); isFooterOnlyOnChange=t;;
	--footer-every)	shift; footerEvery="${1:?}"; shift; footerCapture=(-v finalFooter);;
	--graph-legend)	shift; graphLegendText="$1"; shift;;
	--graph-field)	shift; graphFieldNr="$1"; shift;;
	--footer-legend)
			shift; footerLegendText="$1"; shift;;
	--footer-field)	shift; footerFieldNr="$1"; shift;;
	--field-separator|-F)
			inputDataClassificationArgs+=("$1" "$2"); shift; separator="${1:?}"; shift;;
	--slots-per-day)
			inputDataClassificationArgs+=("$1" "$2"); shift; slotNum="$1"; shift;;
	--day-field)    inputDataClassificationArgs+=("$1" "$2"); shift; dayFieldNr="${1:?}"; shift;;
	--hour-field)   inputDataClassificationArgs+=("$1" "$2"); shift; hourFieldNr="${1:?}"; shift;;
	--count-field)	inputDataClassificationArgs+=("$1" "$2"); shift; countFieldNr="$1"; shift;;
	--default-count)
			inputDataClassificationArgs+=("$1" "$2"); shift; defaultCount="$1"; shift;;
	--split-graph-field)
			inputDataClassificationArgs+=("$1" "$2"); shift; splitFieldNrs+=("$1"); shift;;
	--as)		sparkArgs+=("$1"); shift
			case "$1" in
			    colorbox-calendar)
				sparkArgs+=(color-fullwidth-boxes)
				: ${DISTRIBUTIONOVERTHEMONTH_EMPTY_CELL='  '}
				export SPARK_EMPTY_DATA='  '
				export SPARK_EMPTY=''
				;;
			    green-calendar)
				sparkArgs+=(green-center-boxes)
				: ${DISTRIBUTIONOVERTHEMONTH_COLOR_LEGEND='[01m'}
				: ${DISTRIBUTIONOVERTHEMONTH_COLOR_BORDER='[38;5;241m'}
				: ${DISTRIBUTIONOVERTHEMONTH_COLOR_UNITS='[38;5;241m'}
				: ${DISTRIBUTIONOVERTHEMONTH_COLOR_RESET='[0m'}
				: ${DISTRIBUTIONOVERTHEMONTH_EMPTY_CELL=' '}
				;;
			    green-large-calendar)
				sparkArgs+=(green-double-center-squares)
				: ${DISTRIBUTIONOVERTHEMONTH_COLOR_LEGEND='[01m'}
				: ${DISTRIBUTIONOVERTHEMONTH_COLOR_BORDER='[38;5;241m'}
				: ${DISTRIBUTIONOVERTHEMONTH_COLOR_UNITS='[38;5;241m'}
				: ${DISTRIBUTIONOVERTHEMONTH_COLOR_RESET='[0m'}
				: ${DISTRIBUTIONOVERTHEMONTH_EMPTY_CELL='  '}
				;;
			    *)	sparkArgs+=("$1");;
			esac
			shift
			;;
	--min)		sparkMinArg=("$1" "${2:?}"); shift;shift;;
	--max)		sparkMaxArg=("$1" "${2:?}"); shift;shift;;
	--)		sparkArgs+=("$1"); shift; break;;
	*)		sparkArgs+=("$1"); shift;;
    esac
done
if [ $dayFieldNr -eq $hourFieldNr ]; then
    echo >&2 'ERROR: Hour field cannot be equal to day field.'
    exit 2
elif [ -n "$countFieldNr" ] && [ $countFieldNr -eq $dayFieldNr -o $countFieldNr -eq $hourFieldNr ]; then
    echo >&2 'ERROR: Count field cannot be equal to day / hour fields.'
    exit 2
fi

: ${DISTRIBUTIONOVERTHEMONTH_EMPTY_CELL= }
: ${DISTRIBUTIONOVERTHEMONTH_BORDERS=‚é° ‚é§ ‚é£ ‚é¶}

: ${DISTRIBUTIONOVERTHEMONTH_COLOR_BORDER=}  # for DISTRIBUTIONOVERTHEMONTH_BORDERS
: ${DISTRIBUTIONOVERTHEMONTH_COLOR_LEGEND=}  # for the graph legend
: ${DISTRIBUTIONOVERTHEMONTH_COLOR_FOOTER=}  # for the footer legend
: ${DISTRIBUTIONOVERTHEMONTH_COLOR_UNITS=}   # for the days at the bottom of the chart
: ${DISTRIBUTIONOVERTHEMONTH_COLOR_GRAPH=}   # for spark graph itself
: ${DISTRIBUTIONOVERTHEMONTH_COLOR_RESET=}   # undo the coloring

typeset -a borders=()
[ -n "$DISTRIBUTIONOVERTHEMONTH_BORDERS" ] && IFS='' read -r -d '' -a borders <<<"${DISTRIBUTIONOVERTHEMONTH_BORDERS// /}"
[ ${#borders[@]} -gt 0 ] && borders[-1]="${borders[-1]%$'\n'}"

IFS=$'\n'
renderWith()
{
    awk \
	--field-separator "$separator" \
	-v "graphFieldNr=$graphFieldNr" \
	-v "footerFieldNr=$footerFieldNr" \
	-v "dayFieldNr=$dayFieldNr" \
	-v "hourFieldNr=$hourFieldNr" \
	-v "countFieldNr=$countFieldNr" \
	-v "defaultCount=$defaultCount" \
	-v "slotNum=$slotNum" \
	-v "splitFieldNrList=${splitFieldNrs[*]//\\/\\\\}" \
	-v "emptyCell=${DISTRIBUTIONOVERTHEMONTH_EMPTY_CELL//\\/\\\\}" \
	"$1"'
BEGIN {
    splitFieldNrNum = split(splitFieldNrList, splitFieldNrs, "\n")
    delete count
    init()
}
{
    for (i in splitFieldNrs) {
	sf = splitFieldNrs[i]
	if ($sf != "" && watchedFields[sf] != "" && watchedFields[sf] != $sf) {
	    printSection()

	    delete watchedFields
	    for (sf in splitFieldNrs) {
		if ($sf != "") watchedFields[sf] = $sf
	    }
	    break
	} else if (watchedFields[sf] == "" && $sf != "") {
	    watchedFields[sf] = $sf
	}
    }

    if (graphFieldNr != "" && graphLegend == "") graphLegend = $graphFieldNr
    if (footerFieldNr != "" && footerLegend == "") footerLegend = $footerFieldNr

    slot = int((int($dayFieldNr) - 1) * slotNum + (slotNum > 1 ? int($hourFieldNr) * slotNum / 24 : 0))

    if (countFieldNr == "") {
	count[slot] += 1
    } else if ($countFieldNr ~ /^-?[[:digit:]]+$/) {
	count[slot] += int($countFieldNr)
    } else if (defaultCount != "none") {
	if (defaultCount != "") {
	    count[slot] += defaultCount
	}
    } else {
	printf("%s count in line %d: %s\n", ($countFieldNr == "" ? "Missing" : "Invalid"), NR, $0) > "/dev/stderr"
    }
}
END {
    printSection()
}
'"$2"
}
tally()
{
    renderWith '
function init()
{
    emptyCellWithoutAnsiEscapes = gensub(/\x1b\[[0-9:;]*m/, "", "g", emptyCell)
    cellWidth = (emptyCellWithoutAnsiEscapes == "„ÄÄ" ? 2 : length(emptyCellWithoutAnsiEscapes)) # Rudimentary handling of fullwidth characters (just U+3000 IDEOGRAPHIC SPACE).
}
function printSection(      dayWidth, h, result, s)
{
    if (length(count) == 0) return

    print graphLegend; graphLegend = ""
    print footerLegend; footerLegend = ""

    dayWidth = slotNum * cellWidth
    if (dayWidth >= 2) {
	for (h = 1; h <= 31; ++h) {
	    printf("%-" dayWidth "." dayWidth "s", h)
	}
    } else {
	for (h = 1; h < 31; h += 3) {
	    printf("%-3.3s", h)
	}
	printf(" ") # Already printed 3 * 10 characters - need one more to make up 31 cells.
    }
    printf "\n"

    result = render(count[0])
    for (s = 1; s < 31 * slotNum; ++s) {
	result = result "," render(count[s])
    }
    print result; delete count
}
function render(v)
{
    return (v == "" ? emptyCell : v)
}
'
}
tallyAndPrint()
{
    tally | printDistribution
}
determineCountRange()
{
    typeset -a rangeArgumentRender=()
    [ ${#sparkMinArg[@]} -gt 0 ] \
	|| rangeArgumentRender+=('printf("--min\n%d\n", (min == max && max > 0 ? min - 1 : min))')
    [ ${#sparkMaxArg[@]} -gt 0 ] \
	|| rangeArgumentRender+=('printf("--max\n%d\n", max)')

    renderWith '
function init()
{
    min = 2^PREC
    max = 0
}
function printSection()
{
    for (slot in count) {
	if (count[slot] < min) min = count[slot]
	if (count[slot] > max) max = count[slot]
    }
    delete count
}' \
'
END {
'"${rangeArgumentRender[*]}"'
}
'
}

printDistribution()
{
    unset previousFooter
    local status=99 footer footerCount=0
    while :
    do
	# Each section consists of 4 lines:
	# - legend for graph
	# - legend for footer
	# - footer
	# - comma-separated data
	local graphLegendFromData; IFS=$'\n' read -r graphLegendFromData || break
	local graphLegend="${graphLegendFromData:-$graphLegendText}"
	local footerLegendFromData; IFS=$'\n' read -r footerLegendFromData || break
	local footerLegend="${footerLegendFromData:-$footerLegendText}"
	IFS=$'\n' read -r footer || break
	local data; IFS=$'\n' read -r data || break

	local sparkEmptyOverride; [ -n "${SPARK_EMPTY+t}" ] || sparkEmptyOverride='SPARK_EMPTY="$DISTRIBUTIONOVERTHEMONTH_EMPTY_CELL"'
	local renderedDistribution; renderedDistribution="$(eval "$sparkEmptyOverride" 'spark "${sparkMinArg[@]}" "${sparkMaxArg[@]}" "${sparkArgs[@]}" "$data"')" && status=0 || exit $?

	local legendWidth=$DISTRIBUTIONOVERTHEMONTH_LEGEND_LENGTH

	local B="$DISTRIBUTIONOVERTHEMONTH_COLOR_BORDER" L="$DISTRIBUTIONOVERTHEMONTH_COLOR_LEGEND" F="$DISTRIBUTIONOVERTHEMONTH_COLOR_FOOTER" U="$DISTRIBUTIONOVERTHEMONTH_COLOR_UNITS" G="$DISTRIBUTIONOVERTHEMONTH_COLOR_GRAPH" R="$DISTRIBUTIONOVERTHEMONTH_COLOR_RESET"
	if [ "$isFooter" ]; then
	    if [ -z "$legendWidth" ]; then
		legendWidth=$((${#graphLegend} > ${#footerLegend} ? ${#graphLegend} : ${#footerLegend}))
		[ -n "${borders[0]}" ] || let legendWidth+=1
	    fi

	    if [ "$isFooterOnlyOnChange" ]; then
		if [ -n "${previousFooter+t}" -a "$previousFooter" != "$footer" ]; then
		    printf %s "$finalFooter"
		    finalFooter=
		    footerCount=0
		fi
		previousFooter="$footer"
	    fi
	    if [ -n "$footerEvery" ] && [ $((footerCount % footerEvery)) -eq 0 ]; then
		printf %s "$finalFooter"
	    fi

	    printf "%s%-${legendWidth}.${legendWidth}s%s%s%s%s\\n" "$L" "$graphLegend" "${L:+$R}" "${B}${borders[0]}${B:+$R}" "${G}${renderedDistribution}${G:+$R}" "${B}${borders[1]}${B:+$R}"
	    printf "${footerCapture[@]}" \
		   "%s%-${legendWidth}.${legendWidth}s%s%s%s%s\\n" "$F" "$footerLegend" "${F:+$R}" "${B}${borders[2]}${B:+$R}" "${U}${footer}${U:+$R}" "${B}${borders[3]}${B:+$R}"

	    let footerCount+=1
	else
	    local completeLegend="$graphLegend"; [ -n "$graphLegend" -a -n "$footerLegend" ] && completeLegend+=' '; completeLegend+="$footerLegend"
	    printf "%s%${legendWidth:+-}${legendWidth}${legendWidth:+.}${legendWidth}s%s%s\\n" "$L" "$completeLegend" "${L:+$R}" "${G}${renderedDistribution}${G:+$R}"
	fi
    done

    [ -z "$finalFooter" ] || printf %s "$finalFooter"
    return $status
}

if [ -z "$action" ] && [ ${#splitFieldNrs[@]} -gt 0 ] && [ ${#sparkMinArg[@]} -eq 0 -o ${#sparkMaxArg[@]} -eq 0 ]; then
    # With --split-graph-field, multiple graphs are generated. Unfortunately, the
    # mapping of value ranges to sparklines is restarted for each graph unless the
    # range has been fixed via --min and --max. The user perceives the entire output
    # as one entity; we must not let the re-scaling happen, as it's highly
    # misleading.
    # Sadly, in order to determine the range, we first need to process the entire
    # data once to find the minimum and maximum values. We reuse most of our
    # processing logic by invoking ourselves with --determine-count-range; that
    # extracts the minimum and maximum values as --min and --max command-line
    # parameters, and the withPreprocessedInput command picks those up and then
    # reinvokes ourselves, supplying the original input data once more. The added
    # min/max parameters break the recursion.
    exec withPreprocessedInput --parallel-preprocess \
	--preprocess-exec "${BASH_SOURCE[0]}" --determine-count-range "${inputDataClassificationArgs[@]}" "${sparkMinArg[@]}" "${sparkMaxArg[@]}" \; \
	--exec "${BASH_SOURCE[0]}" '{@}' "${allargs[@]}" \;
fi

${action:-tallyAndPrint}
